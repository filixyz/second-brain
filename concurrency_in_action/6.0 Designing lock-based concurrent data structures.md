What does it mean to design for concurrency? This basically means that multiple threads can access the data structure concurrently,either performing the same operations or distinct operations and each thread will see a self-consistent view of the data structure; Meaning no data is lost, no invariants broken and no problematic race conditions.

Serialization: in which due to the exclusive nature of ownership, by a mutex, a data structure must be bounded by to enable safe concurrent access, threads take turns accessing the data protected by that mutex, if the granularity of the access is too large, it could degrade the access to the data structure from a concurrent one to a sequential one.

So the idea for building efficient data structures for concurrent access is simple: the smaller the protected region, the fewer operations are serialized, and the greater the potential for concurrency.

## Guidelines for designing data structures for concurrency
There are two aspects to consider when designing data structures for concurrent access: Ensuring that the access are safe and enabling genuine concurrent access.

The basics of how data structure can be thread-safe were discussed back in chapter 3:
* Ensure that no thread can see a state where the invariants of the data structure have been broken by the actions of another thread.
* Take care to avoid race conditions inherent in the interface to the data structure by providing functions for complete operations rather than for operation steps.
* Pay attention to how the data structure behaves in the presence of exceptions to ensure that the invariants are not broken.
* Minimize the opportunities for deadlock when using the data structure by restricting the scope of locks and avoiding nested locks where possible.

It is not uncommon for data structures to allow concurrent access from multiple threads that merely read the data structure, whereas a thread that can modify the data structure must have exclusive access.

### A thread safe stack using locks
```c++
#include <exception>
struct empty_stack: std::exception
{
	const char* what() const throw();
};

template <typename T>
class threadsafe_stack
{
private:
	std::stack<T> data;
	mutable std::mutex m;
public:
	threadsafe_stack() {}
	threadsafe_stack(const threadsafe_stack& other){
		std::scoped_lock lk (other.m);
		data = other.data;
	}
	threadsafe_stack& operator=(const threadsafe_stack& other) = delete;
	
	void push(T new_value)
	{
		std::scoped_lock lk (m);
		data.push(std::move(new_value)); // 1
	}
	std::shared_ptr<T> pop()
	{
		std::scoped_lock lk {m};
		if (data.empty()) throw empty_stack{}; // 2
		std::shared_ptr const res {std::make_shared(
			std::move(data.top()) // 3
		)};
		data.pop(); // 4
		return res;
	}
	void pop (T& res_var)
	{
		std::scoped_lock lk {m};
		if (data.empty()) throw empty_stack{};
		res_var = std::move(data.top()); // 5
		data.pop() // 6
	}
	void empty() const
	{
		std::scoped_lock lk (m);
		return data.empty();
	}
}
```
This example was explained in the text. Although this implementation is “sufficient” for safe concurrent access, it is not effective, This implementation will foster lots of serialization between threads; since at any time, only one thread can perform any operation.

Also the stack doesn’t provide any means of waiting for an item to be added so if a thread need to wait, it would need to while loop on the stack `empty()` state and be prepared to catch a possible `empty_stack` exception, while trying to `pop`. Which is quite inefficient.

The queue implementation, in the next section, puts this problem into view and offers a solution (for the inefficient waiting mechanism while popping) via conditional variables

### A thread-safe queue using locks and conditional variables
```c++
template <typename T>
class threadsafe_queue{
private:
	mutable std::mutex mut;
	std::queue<T> data_queue;
	std::conditional_variable data_cond;
public:
	threadsafe_queue() {}
	void push(T new_value) {
		std::scoped_lock lk (mut);
		data_queue.push(std::move(new_value));
		data_cond.notify_one();
	}
	void wait_and_pop(T& res_var){
		std::unique_lock lk (mut);
		data_cond.wait(lk, [this]{return !data_queue.empty();});
		res_var = std::move(data_queue.front());
		data_queue.pop();
	}
	std::shared_ptr<T> wait_and_pop(){
		std::unique_lock lk (mut);
		data_cond.wait(lk, [this]{return !data_queue.empty();});
		std::shared_ptr<T> res {std::make_shared<T>(
			std::move(data_queue.front())
		)};
		data_queue.pop();
		return res;
	}
	bool try_pop(T& res_var){
		std::lock_guard lk (mut);
		if (data_queue.empty())
			return false;
		res_var = std::move(data_queue.front());
		data_queue.pop()
		return true;
	}
	std::shared_ptr<T> try_pop()
	{
		std::lock_guard lk (mut);
		if (data_queue.empty())
			std::shared_ptr<T> {};
		std::shared_ptr<T> res {std::make_shared<T>(
			std::move(data_queue.front())
		)};
		data_queue.pop();
		return res;
	}
	bool empty() const
	{
		std::lock_guard lk (mut);
		return data_queue.empty()
	}
};
```
The code is self explanatory—if confused consult the text. The new `wait_and_pop` are solution to the problem of waiting for a queue entry as we saw with the stack; rather than continuously invoking `empty` to know if there could be a chance you could retrieve an entry; The mechanism needed to effectively wait and retrieve an item is implicitly built into the member function `wait_and_pop`.

The issues with this implementation  and are listed below with their corresponding solutions:
1) In cases where numerous threads  invoked `wait_and_pop()` and a single thread is woken by `data_cond.notify_one()`, that thread could throw an exception in `wait_and_pop`, such as when a new `std::shared_ptr` is being constructed. If this isn’t acceptable, the call should be replaced with `data_cond.notify_all()`, which also comes with it’s own set of issues, since most thread would still have to go back to sleep when acquire the lock and notice that the queue is empty once again.
2) An alternative to the issue imposed by now using `data_cond.notify_all()`, is to guard the construction of the new shared pointer in `wait_and_pop` with a try catch block to catch any exceptions that might be thrown, and in the event that an exception was caught, the catch block should invoke another `data_cond.notify_one` in order to wake up a new thread to handle/replace the prior uncompleted execution.
3) A third alternative would be to move the `std::shared_ptr<>` initialization to the `push()` call and store `std::shared_ptr<>` instance rather than direct data values. Copying the `std::shared_ptr<>` out of the internal `std::queue<>` then can’t throw an exception, so `wait_and_pop()` is safe again. Below is a listing that implements this:
### A thread safe queue holding `std::shared_ptr<>` instance
```c++
template <typename T>
class threadsafe_queue
{
private:
	mutable std::mutex mut;
	std::queue<std::shared_ptr<T>> data_queue;
	std::conditional_variable data_cond;
public:
	void push(T& new_val_){
		std::shared_ptr<T> new_val {std::make_shared<T>(
			std::move(new_val_)
		)};
		std::scoped_lock lk (mut);
		data_queue.push(new_val)
		data_cond.notify_one();
	}
	void wait_and_pop(T& value){
		std::unique_lock lk {mut};
		data_cond.wait(lk, [this]{return !data_queue.empty()});
		value = std::move(*data_queue.front());
		data_queue.pop();
	}
	bool try_pop(T& value){
		std::scoped_lock lk {mut};
		if (data_queue.empty)
			return false;
		value = std::move(*data_queue.front());
		data_queue.pop();
	}
	std::shared_ptr<T> wait_and_pop(){
		std::unique_lock lk {mut};
		data_cond.wait(lk, [this]{return !data_queue.empty();});
		std::shared_ptr<T> res = data_queue.front();
		data_queue.pop();
		return res;
	}
	std::shared_ptr<T> try_pop(){
		std::scoped_lock lk (mut);
		if (data_queue.empty())
			return std::shared_ptr<T>{};
		std::shared_ptr<T> res = data_queue.front();
		data_queue.pop()
		return res;
	}
	bool empty() const
	{
		std::scoped_lock lk(mut);
		return data_queue.empty();
	}
};
```
The code is self explanatory; by moving the construction of shared pointers to the `push` member function, instead of `pop`s; we have eliminated the concern of trying to pop an element but instead being greeted by an exception that could derail the expected execution of `notify_one()`.

But this implementation still has its’ shortcomings:
1) The use of a mutex to protect the entire data structure limits the concurrency capability of the program (due to much serialization)
2) part of the restriction also comes from the use of `std::queue<>`, the text further explains why, i don’t really get it.

## A thread safe-queue using fine-grained locks and conditional variables.

### A simple single threaded queue implemented using a singly linked list
```c++
#include <memory>
#include <iostream>

template <class T>
class simple_queue{
	struct node {
		T data;
		std::unique_ptr<node> next;
		node(T data_): data(std::move(data_)) {}
	};
	std::unique_ptr<node> head;
	node* tail;
public:
	simple_queue(): tail{nullptr} {}
	simple_queue(const simple_queue&) = delete;
	simple_queue& operator=(const simple_queue&) = delete;
	
	void push(T& new_data){
		std::unique_ptr<node> new_node {new node(std::move(new_data))};
		node* new_node_raw_ptr = new_node.get();
		if (tail)
			tail->next = std::move(new_node);
		else
			head = std::move(new_node);
		tail = new_node_raw_ptr;
	}
	std::shared_ptr<T> try_pop(){
		if(!head)
			return std::shared_ptr<T> {};
		std::unique_ptr<node> old_head = std::move(head);
		head = std::move(old_head->next);
		if(!head)
			tail = nullptr;
		return std::make_shared<T>(std::move(old_head->data));
	}
};

int main()
{
	simple_queue<int> q;
	int a = 1;
	int b = 2;
	int c = 3;
	q.push(a);
	q.push(b);
	q.push(c);
	for (int i = 0; i < 3; ++i)
		std::cout << *q.try_pop() << ' ';
	std::cout << '\n';
}
```
This implementation works fine for single threaded usage but for concurrent access a lot of issues arises; Given we have two data items it would not be stupid of us to protect them each with their own mutex, which is what we should do but there a couple of issues that will come with that. These issues do not arise due to the use of mutexes instead thy exist due to inherent design and nature of the data structure:
1) given that `push` modifies both head an tail it would have to lock both mutexes, which should be fine except, both `push` and `pop` access the next pointer, so in the situation that only one element is left in the queue, it would imply that `head==tail`, ergo `head->next == tail->next`  which in theory should require it’s own protection. Because you cant tell if its the same object without reading both `head` and `tail` it implies that for both `push` and `try_pop` we would have to lock both mutexes, which essentially degrades the access to the data structure from a concurrent one to a sequential one, making it no better than it’s prior implementation (the one with no lock and cares not for concurrent access; the implementation above).

The subsection below addresses this dilemma with it’s solution

### Enabling concurrency by separating data
One solution to our problem is separating the head node from the tail node at all times via a dummy node.

For an empty queue that head and tail pointer both point at the dummy node; making it, at all times, that there be at least one node in the queue.

That way if a new object is placed into the queue that dummy node metastasizes from a dummy node to an elemental node holding the appropriate data that was just pushed into the queue and a new replacement dummy node is constructed to be the next linked node to the newly elemental node, the tail pointer can then point and the new dummy node and that cycle continues for each new push.

This approach proves beneficial for concurrency because now `try_pop` doesn’t access `head->next`. if the queue is empty and once we add a new node to the queue (meaning there’s a single elemental node and one dummy node) head and tail pointers now point to different nodes, eradicating the race on `head→next` and `tail→next` that was present in the previous implementation

the new implementation:
### A simple queue with a dummy node
```c++
template <typename T>
class queue
{
private:
	struct node {
		std::shared_ptr<T> data;
		std::unique_ptr<node> next;
	};
	std::unique_ptr<node> head;
	node* tail:
public:
	queue():
		head(new node), tail(head.get())
	{}
	queue (const queue& other) = delete;
	queue& operator=(const queue& other) = delete;
	std::shared_ptr<T> try_pop()
	{
		if (head.get() == tail)
			return std::shared_ptr<T> {};
		std::unique_ptr<node> old_head {std::move(head)};
		head = std::move(old_head->next);
		return std::shared_ptr<T> (old_head->data)
	}
	void push(T new_value)
	{
		std::shared_ptr<T> new_data (std::make_shared<T>(
			std::move(new_value) ));
		std::unique_ptr<node> dummy {new node};
		tail->data = new_data;
		tail->next = std::move(dummy);
		tail = (tail->next).get();
	}
};
```
This new implementation offers lots of opportunities for tuning the queue into a concurrent one with fine grained access, the benefits we can now enjoy are listed:
1)  `push` only access tail, not head; so in concurrent code we’ll only need to lock the `tail_mutex`
2) `try_pop` access both `head` and `tail`, but the access to `tail` is short lived, so it’s mutex retention after acquisition will also be short lived.
3) The biggest gain is `try_pop` and `push` are never operating on the same node, so we no longer need a overarching mutex to handle if `tail==head`. we can have one mutex for tail and a different for head.
so where do we put the locks?
if we aim for the maximum opportunities for concurrency all locks must be held for the shortest possible length of time:
4) for `push`: the mutex is head across all accesses to tail, so it should be acquired right after the dummy node was constructed—right before the first access to tail.
5) for `try_pop`: the mutex for `head` is to be locked first and held until it’s last access. This mutex determines which thread does the popping, so it should be done first. Then for the access to tail, since we need to access tail once its lock should be accessed only for the length of time it takes to read `tail`, This is best done by wrapping the read in a function. Also since the code that needs `head` locked is only a subset of the member, it wold be clearer to wrap that in a function too.
The final code is shown below:
### A thread safe queue with fine grained locking
```c++
template <typename T>
class threadsafe_queue
{
	struct node
	{
		std::shared_ptr<T> data;
		std::unique_ptr<node> next;
	};
	
	std::mutex head_mutex;
	std::unique_ptr<node> head;
	std::mutex tail_mutex;
	node *tail;
	
	node* get_tail()
	{
		std::scoped_lock<std::mutex> tail_lock (tail_mutex);
		return tail;
	}
	std::unique_ptr<node> pop_head()
	{
		std::scoped_lock<std::mutex> head_lock (head_mutex);
		if (head.get() == get_tail())
			return nullptr;
		std::unique_ptr<node> old_head = std::move(head);
		head = std::move(old_head->next);
		return old_head;
	}
public:
	threadsafe_queue():
		head(new node), tail(head.get())
	{}
	threadsafe_queue(const threadsafe_queue& other)=delete;
	threadsafe_queue& operator=(const threadsafe_queue& other)=delete;
	std::shared_ptr<T> try_pop()
	{
		std::unique_ptr<node> old_head=pop_head();
		return old_head?old_head->data:std::shared_ptr<T>();
	}
	void push(T new_value)
	{
		std::shared_ptr<T> new_data (
			std::make_shared<T>(std::move(new_value)));
		std::unique_ptr<node> dummy {new node};
		std::scoped_lock<std::mutex> tail_lock (tail_mutex);
		tail->data = new_data;
		tail->next = std::move(dummy);
		tail = (tail->next).get();
	}
};
```
The text further explains the code with critical lenses, exploring the various ways the invariants where held and how subtle changes could insidiously break those invariants. It worth re-reading if your confused later in the future.

## Waiting For an Item to Pop
Our previous implementations are indeed thread safe but they lack waiting `pop` functions, `pop` overloads that store the retrieved data into a reference variable the caller might provide, let’s fix that.

Modifying push to allow this is fairy easy, to do that we introduce a conditional variable object and after pushing an object we invoke the conditional variable to notify waiting threads via `.notify_one()`at the end of the push function, this works but a small issue arises; if the lock on tail is held just as it is in our previous example, and the conditional variable notification is invoked at the end of the function (while the mutex is held), a thread could awaken only to find out the push function has still not relinquished its hold on the lock, this can be averted by relinquishing the lock on the mutex before the conditional variable invoked to notify sleeping threads, Might be a minor improvement, but might prove important for some cases.

`wait_and_pop` is more complicated, since we have to decide where to what, what the predicate is and which mutex is to be locked. The condition are waiting for is “the queue should not be empty” ergo `head.get() != tail` but since tail is protected by a mutex and we already own the head mutex, its is then encapsulated as `head.get() != get_tail()`. we would need to hold `head_mutex` so we can use our lock on that for the call to `data_cond.wait()`, once the wit logic is added the implementation  is the same as `try_pop()`

The second overload of `try_pop` and the corresponding `wait_and_pop()` overload require careful thought. Since we are replacing the return of `std::shared_ptr<>` retrieved from old head with a copy assignment to the reference value parameter, there’s a potential exception-safety issue. At this point the data item has been removed from the queue and if the copy assignment throws and exception, the just popped of node and it’s data can be lost forever.

A fix to our above issue would be to: 
1) rely on the presupposition that the retrieved type `T` has a no-throw move assignment operator or no-throw swap operation, but this is just being wishful.
2) if we prefer a more general solution used for any type `T` we have to move the potential throwing operation inside the locked region before the node is removed from the list.
An implementation putting all these into actualization will be provided in bits as we go on.

### A thread-safe queue with locking and waiting: internals and interface
```c++
template <typename T>
class threadsafe_queue
{
private:
	struct node
	{
		std::shared_ptr<T> data;
		std::unique_ptr<node> next;
	};
	std::mutex head_mutex;
	std::unique_ptr<node> head;
	std::mutex tail_mutex;
	node* tail;
	std::conditional_variable data_cond;
public:
	threadsafe_queue():
		head(new node), tail (head.get())
	{}
	threadsafe_queue(const threadsafe_queue& other)=delete;
	threadsafe_queue operator=(const threadsafe_queue& other)=delete;
	std::shared_ptr<T> try_pop();
	bool try_pop(T& value);
	std::shared_ptr<T> wait_and_pop();
	void wait_and_pop(T& value);
	void push(T new_value);
	bool empty();
}
```
### A thread-safe queue with locking and waiting: pushing new values
```c++
template <typename T>
void threadsafe_queue<T>::push(T new_value)
{
	
	std::shared_ptr<T> new_data (
		std::make_shared<T>(std::move(new_value)));
	std::unique_ptr<node> dummy {new node};
	{
		std::scoped_lock<std::mutex> tail_lock (tail_mutex);
		tail->data = new_data;
		tail->next = std::move(dummy);
		tail = (tail->next).get();
	}
	data_cond.notify_one();
}
```
### A thread-safe queue with locking and waiting: `wait_and_pop()`
```c++
template <typenma T>
class threadsafe_queue
{
private:
	node* get_tail()
	{
		std::scoped_lock<std::mutex> tail_lock (tail_mutex);
		return tail;
	}
	std::unique_ptr<node> pop_head()
	{
		std::unique_ptr<node> old_head = std::move(head);
		head = old_head->next;
		return old_head;
	}
	std::unique_lock<std::mutex> wait_for_data()
	{
		std::unique_lock<std::mutex> head_lock (head_mutex);
		data_cond.wait(head_lock, [&]{return head.get()!=get_tail();});
		return std::move(head_lock);
	}
	std::unique_ptr<node> wait_pop_head()
	{
		std::unique_lock<std::mutex> head_lock {wait_for_data()};
		return pop_head();
	}
	std::unique_ptr<node> wait_pop_head(T& value)
	{
		std::unique_lock<std::mutex> head_lock {wait_for_data()};
		value = std::move(*head->data);
		return pop_head();
	}
public:
	std::shared_ptr<T> wait_and_pop()
	{
		std::unique_ptr<node> const old_head = wait_pop_head();
		return old_head->data;
	}
	void wait_and_pop(T& new_value)
	{
		std::unique_ptr<node> const old_head = wait_pop_head();
	}
};
```
### A thread safe queue with locking and waiting: `try_pop` and `empty()`
```c++
template <typename T>
class threadsafe_queue
{
private: 
	std::unique_ptr<node> try_pop_head()
	{
		std::scoped_lock<std::mutex> head_lock (head_mutex);
		if (head.get() == get_tail())
			return std::unique_ptr<node>();
		return pop_head();
	}
	std::unique_ptr<node> try_pop_head(T& value)
	{
		std::scoped_lock<std::mutex> head_lock (head_mutex);
		if (head.get() == get_tail())
			return std::unique_ptr<node>();
		value = std::move(*head->next);
		return pop_head();
	}
public:
	std::shared_ptr<T> try_pop()
	{
		std::unique_ptr<node> old_head=try_pop_head();
		return old_head? old_head->data : std::shared_ptr<T>();
	}
	void wait_and_pop(T& value)
	{
		std::unique_ptr<node> const old_head=try_pop_head(value);
		return old_head;
	}
	bool empty()
	{
		std::scoped_lock<std::mutex> head_lock (head_mutex);
		return (head.get()==get_tail());
	}
};
```
The queue we’ve been implementing throughout this chapter is known as an *unbounded queue*

## Designing more complex lock-based data structures
This section explains how to design thread safe maps and lists

### Designing  a map data structure for fine grained locking
There are three common ways of implementing an associative container like a look up table:
1) As a binary tree, such as a red black tree
2) A sorted array,
3) or A hash table
The only viable option with high regard for efficiency here is a hash table, the hash table will be composed of buckets in which the access to an individual bucket is a function of the hash-tables chosen hash function, luckily c++ provides `std::hash<>` which is a template class/function? that can be used to specialize a hash function for different types (both fundamental and container types)

Here is a possible implementation of a thread-safe lookup table built upon the hash table data structure:
```c++
template < class Key, class Value, class Hash=std::hash<Key> >
class threadsafe_lookup_table
{
private:
	class bucket_type{
		typedef std::pair<Key, Value> bucket_value;
		typedef std::list<bucket_value> bucket_data;
		typedef bucket_data::iterator bucket_iterator;
		
		mutable std::shared_mutex mutex;
		bucket_data data;
		
		bucket_iterator find_entry_for(Key const& key) const
		{
			return std::find_if(data.begin(), data.end(), 
			[&](bucket_value const& item){return item.first==key;}
			);
		}
	public:
		Value value_for(Key const& key, Value const& default_value) const
		{
			std::shared_lock<std::shared_mutex> lk (mutex);
			auto const found=find_entry_for(key);
			return found!=data.end() ? found->second : default_value;
		}
		void add_or_update_mapping(Key const& key, Value const& value)
		{
			std::unique_lock<std::shared_mutex> lk (mutex);
			auto const found=find_entry_for(key);
			if (found==data.end())
				data.push_back(bucket_value(key, value));
			else
				found->second=value;
		}
		void remove_mapping(Key const& key)
		{
			std::unique_lock<std::shared_mutex> lock (mutex);
			auto const found=find_entry_for(key);
			if (found!=data.end())
				data.erase(found);
		}
	};
	
	std::vector<std::unique_ptr<bucket_type>> buckets;
	Hash hasher;
	bucket_type& get_bucket(Key const& key) const
	{
		std::size_t const index=hasher(key)%buckets.size();
		return *buckets[index];
	}
	
public:
	typedef Key key_type;
	typedef Value mapped_type;
	typedef Hash hash_type;
	
	threadsafe_lookup_table(
		unsigned num_buckets=19, Hash const hasher_=Hash()
	) : buckets(num_buckets), hasher(hasher_)
	{
		for (unsigned i=0; i<num_buckets; ++i)
			buckets[i].reset(new bucket_type);
	}
	
	threadsafe_lookup_table(threadsafe_lookup_table const&)=delete;
	threadsafe_lookup_table& operator=(threadsafe_lookup_table const&)
		=delete;
	
	Value value_for(Key const& key,
		Value const& default_value=Value()) const
	{
		return get_bucket(key).value_for(key, default_value);
	}
	void add_or_update_mapping(Key const& key, Value const& value)
	{
		get_bucket(key).add_or_update_mapping(key, value);
	}
	void remove_mapping(Key const& key)
	{
		get_bucket(key).remove_mapping(key);
	}
};
```

#### Obtaining contents of `threadsafe_lookup_table` as `std::map`
This member function enables us get a snapshot of all key-value pairs in the lookup table as a map.
```c++
std::map<Key, Value> threadsafe_lookup_table::get_map() const
{
	std::vector<std::unique_lock<std::shared_mutex>> locks;
	for (unsigned i=0; i<buckets.size(); ++i)
		locks.push_back(
			std::unique_lock<std::shared_mutex>(buckets[i].mutex)
		);
	std::map<Key, Value> res;
	for (unsigned i=0; i<buckets.size(); ++i)
	{
		for(bucket_iterator current=buckets[i]->data.begin();
			current!=buckets[i]->data.end();
			++begin)
		{
			res.insert(*current);
		}
	}
	return res;
}
```

### Writing thread safe list using locks
```c++
template <typename T>
class threadsafe_list
{
	struct node
	{
		std::mutex m;
		std::shared_ptr<T> data;
		std::unique_ptr<node> next;
		node():
			next()
		{}
		node(T const& data_):
			data(std::make_shared<T>(data_))
		{}
	};
	node head;
public:
	threadsafe_list() {}
	~threadsafe_list()
	{
		remove_if([](node const&){return true;});
	}
	threadsafe_list(threadsafe_list const& other) =delete;
	threadsafe_list& operator=(threadsafe_list const& other) =delete;
	
	void push_front(T const& value)
	{
		std::unique_ptr<node> new_node(new node(value));
		std::scoped_lock<std::mutex> head_lock(head.m);
		new_node->next = std::move(head.next);
		head.next = std::move(new_node);
	}
	
	template <typename Function>
	void for_each(Function f)
	{
		node* current=&head;
		std::unique_lock<std::mutex> lk (head.m);
		while (node* const next=current->next.get())
		{
			std::unique_lock<std::mutex> next_lk (next->m);
			lk.unlock();
			f(*next->data);
			current=next;
			lk=std::move(next_lk);
		}
	}
	template <typename Predicate>
	std::shared_ptr<T> find_first_if(Predicate p)
	{
		node* current=&head;
		std::unique_lock<std::mutex> lk (head.m);
		while (node* const next=current->next.get())
		{
			std::unique_lock<std::mutex> next_lk(next->m);
			lk.unlock();
			if(p(*next->data))
				return next->data;
			current=next;
			lk=std::move(next_lk);
		}
		return std::shared_ptr<T>();
	}
	template <typename Predicate>
	void remove_if(Predicate p)
	{
		node* current=&head;
		std::unique_lock<std::mutex> lk (head.m);
		while(node* const next = current->next.get())
		{
			std::unique_lock<std::mutex> next_lk(next->m);
			if(p(*next->data))
			{
				std::unique_ptr<node> old_node (std::move(*next));
				current->next = std::move(next->next);
				next_lk.unlock();
			}
			else
			{
				lk.unlock();
				current=next;
				lk = std::move(next_lk);
			}
		}
	}
};
```