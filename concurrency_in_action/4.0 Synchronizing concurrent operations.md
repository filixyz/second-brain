Sometimes threads need to wait for another thread to perform a specific operation, C++ provides mechanism for the synchronization of threads to perform aggregate actions via *conditional variables* and *futures*.

This chapter explains synchronization in concurrent programming

## Waiting for an event or other condition
A thread might require another thread to accomplish some operation on a shared data before it itself can complete it’s own operation, To synchronize this action we might require the we could make the waiting thread keep checking a “completed” flag in the shared data (protected by a mutex), to see is the waited'-for thread has completed its required action and updated the flag to signal it has completed its action, the issue with this is that waited on thread continuously consumes valuable resources (that could be beneficial to the waited-for thread) on the trivial task that is “checking” and possibly when the waiting thread locks the mutex of the shared data, the waited-for thread cannot access the shared data to update the flag for completed, if it does completes its task; what can we do here? a solution can be to limit the frequency (by a some time value) in which the waiting thread actually checks the completed flag, this can be done by making the waiting thread sleep for some amount for time in-between each successive checks:
```c++
bool completed_flag;
std:mutex m;

void do_something();
void check_if_completed_then_do_something()
{
	std::unique_lock lk (m);
	while(!flag){
		lk.unlock();
		std::this_thread::sleep_for(std::chrono::milliseconds(100));
		lk.lock();
	}
	do_something();
}
```
Although this is an improvement from making the thread zombie-shly check the flag continuously, getting an adequate timing can prove to be tricky, Luckily C++ provides  *conditional variables* to battle this

## Conditional variable mechanism
Conceptually a conditional variable is associated to an event or some condition an one or more threads can wait for that condition to be satisfied, then once the thread modifying the event completes the waited-for event it can now notify the threads waiting on the conditional variable prompting them to wake up and continue their processing.

## Waiting for a condition with condition variables
C++ standard offers two implementation of a conditional variable; `std::conditional_variable` and `std::conditional_variable_any`, the former exclusive operates with the generic `std::mutex` , while the other works with whatever construct that satisfies the mutex concept, hence heavier in size and poses computational overhead compared to it’s former.

`std::conditional_variable` should always be preferred except where additional flexibility is required, Below is an example with it:
```c++
std::queue<data_chunk> data_queue;
std::mutex m;
std::conditional_variable cond;

void data_preparation_thread()
{
	const data_chunk data=prepare_data();
	{
		std::scoped_lock lk(mutex);
		data_queue.push(data);
	}
	cond.notify_one();
}

void data_processing_thread()
{
	while(true)
	{
		std::unique_lock<std::mutex> lk (m);
		cond.wait(lk, []{ return !data_queue.empty(); });
		data_chunk data = data_queue.front();
		data_queue.pop();
		lk.unlock();
		process(data);
		if(is_last_chunk(data)) break;
	}
}
```
In this code, the `data_queue` is used as a means of relay between the preparation thread and the processing thread, now when a data chunk is successfully prepared, the preparation thread relinquishes its lock and threads waiting via the conditionally variables are notified via `cond.notify_one()`.

Say now a processing thread acquires the lock to the queue before the preparation thread could prepare any data for it process, the `cond.wait()` conditional variable member function checks if the predicate passed into it is `true`, if its not it takes the lock passed into it, unlocks it (which explains why `std::unique_lock`) and its chain of execution is blocked—waiting, now lets say the preparation thread was able to acquire the lock, it prepares the data, loses the lock and then `cond.notify_one()` is invoked. This wakes the previously waiting threads for processing. They acquire the lock, `cond.wait()` evaluates its predicate and sees its `true`, `lk` is left untouched (still locked) and its processing commences, with unlocking wherever necessary.


The flexibility of `std::unique_lock` in the processing thread allows us in situations when we have data to process, to relinquish “the lock” so we don’t process the data, which could be time consuming, while holding a lock.

## Building a thread-safe queue with conditional variables
When building a container like a queue that will be subjected to concurrent operations, we need to make it thread-safe, A way of designing the container to be thread safe is making the interface of the actual container simpler in such a way that a handle that could effect the desired output of another handle running on a separate thread are safe from each other.

We can achieve this by merging such handles to a single handle, so that single handle takes account of the effects of both individual handles and manages them in a single coherent state that checkmates each other to ensure and enforce the desired output is gotten.

Also not so important handles that could affect the desired concurrent operation of the container should be `=delete`d or discarded from the implementation.


for example: the `std::queue` interface could be streamlined from:

![std-queue](src/imgs/std-queue.png)

if we can ignore the construction, assignment and swap operations, we notice we are left with three groups of main operations:
* Those than query the state of the whole queue (`empty()` and `size()`)
* Those that query the elements of the queue (`front()` and `back()`)
* And those that modify the queue (`push()`, `pop()` and `emplace()`)

now these handles individually can prove cumbersome in concurrent program—threatening insidious race conditions, but we can eliminate this by merging similar handles and discarding counter-productive handles

Though when using a thread to pass shared data, the receiving thread usually needs to wait for data so we provide 2 variants of `pop()`:
* `try_pop()`; this tries to pop and always return a boolean to indicate failure or success.
* `wait_and_pop()`: if the queue is empty; waits for the queue not to be empty so it can execute a successful `pop()`.

The interface would be streamlined to resemble this:

![thread_safe](src/imgs/thread_safe.png)

The implementation:
```c++
#include <memory>
#include <mutex>
#include <condition_variable>
#include <queue>

template <typename T>
class threadsafe_queue
{
private:
	mutable std::mutex m;
	std::queue<T> safe_queue;
	std::condition_variable cond;
public:
	threadsafe_queue() {}
	threadsafe_queue(const threadsafe_queue& other)
	{
		std::scoped_lock lk (m);
		safe_queue=other.safe_queue;
	}
	threadsafe_queue& operator=(const threadsafe_queue& other)=delete;

	void push(T new_value)
	{
		std::scoped_lock lk (m);
		safe_queue.push(new_value);
		cond.notify_one();
	}
	bool try_pop(T& value)
	{
		std::scoped_lock lk (m);
		if (safe_queue.empty()) return false;
		value=safe_queue.front();
		safe_queue.pop();
		return true;
	}
	std::shared<T> try_pop()
	{
		std::scoped_lock lk (m);
		if(safe_queue.empty()) return nullptr;
		std::shared_ptr<T> res (std::make_shared<T>(safe_queue.front()));
		safe_queue.pop();
		return res;
	}
	void wait_and_pop(T& value)
	{
		std::unique_lock lk (m);
		cond.wait(lk, []{ return !safe_queue.empty(); });
		value=safe_queue.front();
		safe_queue.pop();
	}
	std::shared_ptr<T> wait_and_pop()
	{
		std::unique_lock lk (m);
		cond.wait(lk, []{ return !safe_queue.empty(); });
		std::shared_ptr<T> res (std::make_shared<T>(safe_queue.front()));
		safe_queue.pop();
		return res;
	}
	bool empty() const
	{
		std::scoped_lock lk (m);
		return safe_thread.empty();
	}
};
```
